{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40092668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('Bank_Personal_Loan_Modelling.csv')\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da66eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3635e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "#unsqueeze function removes all the tensors whose dimension=1\n",
    "y_train = torch.from_numpy(y_train).float().unsqueeze(1)\n",
    "y_test = torch.from_numpy(y_test).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db00172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        ''' Linear1 is the input layer\n",
    "            Linear2 is the hidden layer \n",
    "        '''\n",
    "        self.layer1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(hidden_size, output_size)\n",
    "        '''\n",
    "            We are using binary cross-entropy loss function (BCELoss)\n",
    "            and therefore require the inputs to be in the range of 0-1\n",
    "            So, we use sigmoid function to do that.'''\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        ''' First you enter layer1(input layer) and then your output from layer1 \n",
    "        passes a ReLu and then enters layer2 (hidden layer); \n",
    "        whatever outputs from layer2 goes through a sigmoid. \n",
    "        Output of the sigmoid function is the final output'''\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd0b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AntColonyOptimization():\n",
    "    def __init__(self, ant_count, epochs, lr, beta, decay, pheromone_level, size):\n",
    "        self.ant_count = ant_count\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.beta = beta\n",
    "        self.decay = decay\n",
    "        self.pheromone_level = pheromone_level\n",
    "        self.size = size\n",
    "        self.pheromone = np.ones((size, size)) #pheromone matrix full of ones\n",
    "        self.shortest_path = np.zeros((1, size))\n",
    "        self.shortest_path_length = float(\"inf\") #shortest path has been set to infinity\n",
    "        \n",
    "    def optimize(self, model, X, y):\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        '''SGD is Stochastic Gradient Descent'''\n",
    "        optimizer = optim.SGD(model.parameters(), lr=self.lr)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for ant in range(self.ant_count):\n",
    "                outputs = model(X)\n",
    "                #criterion( input , target )\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                self.update_pheromone(loss)\n",
    "            self.evaporate()\n",
    "        return self.shortest_path\n",
    "        \n",
    "    def prob(self, pheromone, heuristic):\n",
    "        '''Assign probability to each path taken'''\n",
    "        probabilities = self.prob(pheromone, heuristic)\n",
    "        numerator = np.power(pheromone, self.beta) * np.power(heuristic, self.beta)\n",
    "        denominator = np.sum(numerator)\n",
    "        probabilities = numerator / denominator\n",
    "        return probabilities\n",
    "        \n",
    "    def update_pheromone(self, loss):\n",
    "        fitness = 1/loss\n",
    "        ''' This function basically helps us choose the next path/update shortest path\n",
    "            If the fitness is less than the shortest path's length, \n",
    "            Then shortest path length = fitness\n",
    "            Shortest path is the one with the pheromones'''\n",
    "        if fitness < self.shortest_path_length:\n",
    "            self.shortest_path_length = fitness\n",
    "            self.shortest_path = self.pheromone\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                '''this is done to allow some level of uncertainty as we dont know\n",
    "                how many ants travelled the path and how much pheromones changed'''\n",
    "                self.pheromone[i, j] *= (1 - self.decay)\n",
    "                self.pheromone[i, j] += self.pheromone_level/fitness\n",
    "                \n",
    "    def evaporate(self):\n",
    "        '''Apply decay on the pheromones because they evaporate with time'''\n",
    "        self.pheromone *= self.decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e762fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rhea Pandita\\AppData\\Local\\Temp\\ipykernel_3596\\2567019472.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = torch.tensor(loss) #this is done to get the numerical loss part only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 ; loss=0.2944999933242798\n",
      "Epoch 10 ; loss=0.2944999933242798\n",
      "Epoch 20 ; loss=0.2944999933242798\n",
      "Epoch 30 ; loss=0.2944999933242798\n",
      "Epoch 40 ; loss=0.2944999933242798\n",
      "Epoch 50 ; loss=0.2944999933242798\n"
     ]
    }
   ],
   "source": [
    "'''Create an instance of the classes AntColony and ACO'''\n",
    "model = NeuralNet(13,5,1)\n",
    "optimizer = AntColonyOptimization(ant_count=10, epochs=100, lr=0.1, beta=2, decay=0.5\n",
    "                                  , pheromone_level=100, size=5)\n",
    "\n",
    "'''process'''\n",
    "inputs = Variable(torch.randn(1, 13))\n",
    "targets = Variable(torch.randn(1, 1))\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "for i in range(51):\n",
    "    optimizer.optimize(model, X_train, y_train)\n",
    "    output = model(X_train)\n",
    "    loss = loss_fn(output, y_train)\n",
    "    loss.backward()\n",
    "    loss = torch.tensor(loss) #this is done to get the numerical loss part only\n",
    "    if i%10 == 0:\n",
    "        print(f\"Epoch {i} ; loss={loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
